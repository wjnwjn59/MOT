DATA:
  MAX_SAMPLE_INTERVAL: 200
  MAX_JUMP: 70
  MEAN:
  - 0.485
  - 0.456
  - 0.406
  SEARCH:
    NUMBER: 5
    CENTER_JITTER: 4.5
    FACTOR: 5.0
    SCALE_JITTER: 0.5
    SIZE: 384
  STD:
  - 0.229
  - 0.224
  - 0.225
  TEMPLATE:
    CENTER_JITTER: 0
    FACTOR: 2.0
    SCALE_JITTER: 0
    SIZE: 192
    NUMBER: 1
  TRAIN:
    DATASETS_NAME:
    - GOT10K_train_full
    DATASETS_RATIO:
    - 1
    SAMPLE_PER_EPOCH: 60000
    CLS_ANN_DIR: "../../data/train_maritime_env_clf_annts"

MODEL:
  NEW_HIP: True
  PRETRAIN_FILE: "DropTrack_k700_800E_got10k.pth.tar"
  EXTRA_MERGER: False
  RETURN_INTER: False
  MAX_MEM: 150
  HIDDEN_DIM: 768  # CLS token dimension from ViT backbone
  BOTTLENECK_DIM: 256  # Fusion layer output dimension
  BACKBONE:
    TYPE: vit_base_patch16_224_ce
    STRIDE: 16
    CE_LOC: [3, 6, 9]
    CE_KEEP_RATIO: [1, 1, 1]
    CE_TEMPLATE_RANGE: 'CTR_POINT'
  HEAD:
    TYPE: CENTER
    NUM_CHANNELS: 256
  CLS_HEAD:
    NUM_CLASSES: 10  # Maritime tracking challenges
    HIDDEN_DIM: 512  # Classification MLP hidden dimension
    DROPOUT: 0.1  # SimTrackMod uses 0.1 dropout

TRAIN:
  BACKBONE_MULTIPLIER: 0.1
  DROP_PATH_RATE: 0.1
  BATCH_SIZE: 2
  EPOCH: 100
  GIOU_WEIGHT: 2.0
  L1_WEIGHT: 5.0
  GRAD_CLIP_NORM: 0.1
  LR: 0.0001
  LR_DROP_EPOCH: 80
  NUM_WORKER: 8
  OPTIMIZER: ADAMW
  PRINT_INTERVAL: 50
  SCHEDULER:
    TYPE: step
    DECAY_RATE: 0.1
  VAL_EPOCH_INTERVAL: 100
  WEIGHT_DECAY: 0.0001
  AMP: False
  CE_START_EPOCH: 20
  CE_WARM_EPOCH: 80
  FREEZE_LAYERS: [0]
  # Classification specific (SimTrackMod architecture)
  CLS_WEIGHT: 1.0  # Weight for classification loss
  CLS_LOSS_TYPE: "CE"  # Options: CE, FOCAL, LABEL_SMOOTH
  CLS_FOCAL_ALPHA: 0.25
  CLS_FOCAL_GAMMA: 2.0
  CLS_LABEL_SMOOTHING: 0.1
  FREEZE_CLS_EPOCH: -1  # Freeze cls branch after this epoch (-1 = never)
  # Two-stage training (SimTrackMod strategy)
  TWO_STAGE: False  # Set to True to enable two-stage training
  STAGE1_EPOCHS: 30  # Stage 1: freeze backbone, train cls head only
  STAGE1_LR: 1e-3  # Higher LR for classification head training
  STAGE2_EPOCHS: 20  # Stage 2: fine-tune entire model
  STAGE2_LR: 1e-5  # Lower LR for full model fine-tuning
  FREEZE_BACKBONE_STAGE1: True  # Freeze backbone in stage 1

TEST:
  EPOCH: 96
  SEARCH_FACTOR: 5.0
  SEARCH_SIZE: 384
  TEMPLATE_FACTOR: 2.0
  TEMPLATE_SIZE: 192

