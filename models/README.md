# ğŸŒŠ MVTD: Maritime Visual Tracking Dataset

**MVTD** (Maritime Visual Tracking Dataset) is a benchmark dataset and codebase designed to support the **development**, **training**, and **evaluation** of visual tracking models in challenging **maritime environments**.


![Block_Diagram](assets/Block_Diagram.png)


This repository includes:
- ğŸ“¦ Tools for model training and testing  
- ğŸ¤– Pretrained model weights  
- ğŸ›  Scripts for running experiments  
- ğŸ“ User-configurable dataset interface  

---

## ğŸ§­ Overview

Maritime tracking involves challenges such as:
- Motion blur from camera or water movement  
- Occlusion by waves or vessels  
- Reflection and glare on the water  

**MVTD** addresses these with high-quality data and robust baseline models to accelerate research in this domain.

---

## ğŸš€ Getting Started

### âœ… Step 1: Clone the Repository

    git clone https://github.com/AhsanBaidar/MVTD.git  
    cd MVTD  

### âœ… Step 2: Install Dependencies

    pip install torch torchvision numpy pillow

---

## ğŸ“‚ Dataset Setup

You need to put your own images in the folders below (Our dataset will be released on paper acceptance):  
The folder and annotation structure of MVTD follows the widely adopted GOT-10k dataset format,  
organizing training videos into subfolders containing frames and annotation files:

    MVTD/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ video1/
    â”‚   â”‚   â”œâ”€â”€ frame0001.jpg
    â”‚   â”‚   â”œâ”€â”€ frame0002.jpg
    â”‚   â”‚   â”œâ”€â”€ ...
    â”‚   â”‚   â”œâ”€â”€ groundtruth.txt
    â”‚   â”‚   â”œâ”€â”€ absence.label
    â”‚   â”‚   â”œâ”€â”€ cut_by_image.label
    â”‚   â”‚   â””â”€â”€ cover.label
    â”‚   â”œâ”€â”€ video2/
    â”‚   â”‚   â”œâ”€â”€ frame0001.jpg
    â”‚   â”‚   â”œâ”€â”€ frame0002.jpg
    â”‚   â”‚   â”œâ”€â”€ ...
    â”‚   â”‚   â”œâ”€â”€ groundtruth.txt
    â”‚   â”‚   â”œâ”€â”€ absence.label
    â”‚   â”‚   â”œâ”€â”€ cut_by_image.label
    â”‚   â”‚   â””â”€â”€ cover.label
    â”‚   â””â”€â”€ ...
    â””â”€â”€ test/
        â”œâ”€â”€ video1/
        â”‚   â”œâ”€â”€ frame0001.jpg
        â”‚   â”œâ”€â”€ frame0002.jpg
        â”‚   â”œâ”€â”€ ...
        â”‚   â””â”€â”€ groundtruth.txt
        â”œâ”€â”€ video2/
        â”‚   â”œâ”€â”€ frame0001.jpg
        â”‚   â”œâ”€â”€ frame0002.jpg
        â”‚   â”œâ”€â”€ ...
        â”‚   â””â”€â”€ groundtruth.txt
        â””â”€â”€ ...

---

## ğŸ“¥ Pretrained Weights

Download the pretrained weights and place them respective folders as inside the link:  
ğŸ‘‰ [**Download Weights Here**](https://kuacae-my.sharepoint.com/:f:/g/personal/ahsan_bakht_ku_ac_ae/Evdzhoi7zddBrMg8WCUA1_wBW_-HUnx602doajk9oK9-Kw?e=ItMjwl)  

Note: For SLTTrack and TransT trackers, please place the pretrained weight files inside the directory:
pytracking/Networks/weight_file/

---

## âš™ï¸ Data Specifications

For Training, you need to modify the files under subfolder data_specs in each tracker folder.


## ğŸ§ª Running the Model

Use the included shell script to run training or testing:

    bash run_command.sh tracker_name test/train

You can modify the script to:
- Switch between training and testing  
---


## ğŸ“š Citation

If you use **MVTD** in your work, please cite:

    @article{bakht2025mvtd,
      author = {Bakht, Ahsan Baidar and Din, Muhayy Ud and Javed, Sajid and Hussain, Irfan},
      title = {MVTD: A Benchmark Dataset for Maritime Visual Object Tracking},
      year = {2025},
      journal = {arXiv preprint arXiv:2506.02866}
    }

---


## Acknowledgments

This work is based on various open-source visual tracking algorithms. We gratefully acknowledge the original authors and communities for their valuable contributions.


---
